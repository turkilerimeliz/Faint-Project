{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6da365c",
   "metadata": {},
   "source": [
    "###  Faint Dataset - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aef9e960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import neccessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "from tsfresh import extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4794eda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a909635d",
   "metadata": {},
   "source": [
    "#### Read and combine CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed4f91e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to return csv_files related to given stage (t)\n",
    "\n",
    "def create_folder (path,search_key):\n",
    "    # create a folder name list to show filtered folder names -- keep only those with stage 4 \n",
    "    file_name=[]\n",
    "    for item in os.listdir(path):\n",
    "        for key in search_key: \n",
    "            if key in  item:\n",
    "                file_name.append(item)\n",
    "    return file_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "950447ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Produced master folder for stage 1\n",
      "INFO:root:Produced master folder for stage 2\n",
      "INFO:root:Produced master folder for stage 4\n"
     ]
    }
   ],
   "source": [
    "# a for loop to create master dataset for several stages (stage 1, 2 and 4-5-6 as combined)\n",
    "\n",
    "search={1:[\"01.csv\"], 2:[\"02.csv\"], 4:[\"_04\",\"-04\",\",04\"]}\n",
    "\n",
    "stages=[1,2,4]\n",
    "\n",
    "# define folder path \n",
    "folder_path ='C:\\\\Users\\\\mtyur\\\\Desktop\\\\FAINT\\\\datain'\n",
    "\n",
    "for i in stages:\n",
    "    \n",
    "    # define a key will be used for file search\n",
    "    search_key = search[i]\n",
    "    \n",
    "    # create a list to report file paths\n",
    "    files=create_folder(folder_path, search_key)\n",
    "    \n",
    "    # create empty dataset \n",
    "    df_s= pd.DataFrame()\n",
    "\n",
    "    # loop to read files and append all csv files to create a master dataset \n",
    "    for file in files: \n",
    "    \n",
    "        # read file\n",
    "        df = pd.read_csv( rf'C:\\\\Users\\\\mtyur\\\\Desktop\\\\FAINT\\\\datain\\\\{file}')\n",
    "\n",
    "        # extract donor id: (extract the numbers corresponding donor_id)\n",
    "        donor_id = re.findall(r'\\d+', file)[0] \n",
    "\n",
    "        # trim column names - use lower cases\n",
    "        df.columns=df.columns.str.strip().str.lower()\n",
    "\n",
    "        # keep subset of variables\n",
    "        df_selected = df[['timestamp','au01_r', 'au02_r', 'au04_r', 'au05_r', 'au06_r', 'au07_r', 'au09_r', 'au10_r', 'au12_r', 'au14_r', 'au15_r', 'au17_r', 'au20_r',\n",
    "                      'au23_r', 'au25_r', 'au26_r', 'au45_r']].copy()\n",
    "\n",
    "        # add donor id - change type of column \n",
    "        df_selected['donor_id'] = donor_id\n",
    "        df_selected['stage'] = i\n",
    "        df_selected['donor_id'] = df_selected['donor_id'].astype('int64')\n",
    "\n",
    "        # create a master dataset for donation stage\n",
    "        df_s =pd.concat([df_s, df_selected], ignore_index=True)\n",
    "        \n",
    "    # create seperate master dataset for each stage \n",
    "    if i == 1:\n",
    "        df1 = df_s.copy()\n",
    "    elif i == 2:\n",
    "        df2 = df_s.copy()  \n",
    "    else: \n",
    "        df4 = df_s.copy() # although it named as df4, it also includes data from stage 3, 5 and 6\n",
    "        \n",
    "    logging.info(f'Produced master folder for stage {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0012aa",
   "metadata": {},
   "source": [
    "#### Extract timestamps to identify the time point --> needle inserted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbf5c37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload timestamp dataset\n",
    "filepath_t =  rf'C:\\Users\\mtyur\\Desktop\\FAINT\\datain\\FAINT_timestamp.csv'\n",
    "df_time= pd.read_csv(filepath_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ed4b2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter stage  4 and create new dataframes\n",
    "df_t4=df_time[(df_time['Time_point'] == 4)][['ID', 'start (seconds)']]. copy()\n",
    "\n",
    "# rename columns \n",
    "df_t4.rename(columns={'start (seconds)':'stage4'}, inplace=True)\n",
    "\n",
    "# rename id as donor_id --> it will be important for following steps\n",
    "df_t4.rename(columns={'ID':'donor_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a44df0",
   "metadata": {},
   "source": [
    "#### Combine starting and ending points to filter stage 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc10edbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dataset using id \n",
    "df4_merge=pd.merge(df4, df_t4, on='donor_id', how='left')\n",
    "\n",
    "# filter dataset based on stage4 starting and stage5 starting timestamp\n",
    "df4_final=df4_merge[df4_merge['timestamp']<df4_merge['stage4']].copy()\n",
    "\n",
    "# drop treshold variables\n",
    "df4_final.drop(columns=['stage4'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f139ecad",
   "metadata": {},
   "source": [
    "#### Produce continues time flow from stage 1 to stage 4 (exclude stage 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "752e1f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append dataset from the first 3 stages:  \n",
    "df_124 =pd.concat([df1, df2, df4_final], ignore_index=True)\n",
    "# sort dataset \n",
    "df_124.sort_values(by=['donor_id', 'stage', 'timestamp'], inplace=True)\n",
    "# reset index\n",
    "df_124.reset_index(drop=True, inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a28e3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract min and max timestamps by donor id and stage \n",
    "df124_max=df_124.groupby(['donor_id', 'stage'])['timestamp'].agg(['min', 'max']).reset_index()\n",
    "\n",
    "# identify max timestamps from stage 1 and 2\n",
    "for i in [1, 2]:\n",
    "    df124_max[f's{i}_max']=df124_max.groupby('donor_id')['max'].shift(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7af1fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust timestamps to create continuous data flow\n",
    "for i in  [1, 2, 4]:\n",
    "    if i ==1:\n",
    "        df124_max.loc[df124_max['stage'] == i, 'add_timestamp'] = 0\n",
    "    else:\n",
    "        df124_max.loc[df124_max['stage'] == i, 'add_timestamp'] =  df124_max['s1_max'].add(df124_max['s2_max'], fill_value=0) + 0.04*(i-1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0f852ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only necessary variables\n",
    "df124_max=df124_max[['donor_id', 'stage', 'add_timestamp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69f3f9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge master dataset with the dataset reporting number of seconds should be added to produce continues data flow (stage 1 to stage 4)\n",
    "df124_final=pd.merge(df_124, df124_max, on=['donor_id', 'stage'], how='left')\n",
    "\n",
    "# recode timestamp --> allows to produce continues data flow from stage 1 to stage 3.\n",
    "df124_final['timestamp']=df124_final['timestamp'].add(df124_final['add_timestamp'], fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c156d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop stage variable\n",
    "df124_final.drop(columns=['stage', 'add_timestamp'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "087b1da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define output file\n",
    "output_raw = 'dataout\\\\df124_intensities_raw.csv'\n",
    "df124_final.to_csv(output_raw, index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3c6e899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3362818"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of datapoints \n",
    "df124_final.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87ab6fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp    3362818\n",
       "au01_r       3362818\n",
       "au02_r       3362818\n",
       "au04_r       3362818\n",
       "au05_r       3362818\n",
       "au06_r       3362818\n",
       "au07_r       3362818\n",
       "au09_r       3362818\n",
       "au10_r       3362818\n",
       "au12_r       3362818\n",
       "au14_r       3362818\n",
       "au15_r       3362818\n",
       "au17_r       3362818\n",
       "au20_r       3362818\n",
       "au23_r       3362818\n",
       "au25_r       3362818\n",
       "au26_r       3362818\n",
       "au45_r       3362818\n",
       "donor_id     3362818\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of non-missing observations for each column.\n",
    "df124_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2ff55fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp    0\n",
       "au01_r       0\n",
       "au02_r       0\n",
       "au04_r       0\n",
       "au05_r       0\n",
       "au06_r       0\n",
       "au07_r       0\n",
       "au09_r       0\n",
       "au10_r       0\n",
       "au12_r       0\n",
       "au14_r       0\n",
       "au15_r       0\n",
       "au17_r       0\n",
       "au20_r       0\n",
       "au23_r       0\n",
       "au25_r       0\n",
       "au26_r       0\n",
       "au45_r       0\n",
       "donor_id     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for NaN values\n",
    "df124_final.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606bf956",
   "metadata": {},
   "source": [
    "#### Use tsfresh package to produce  descriptive statistics for each stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a7535c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters will be used for tsfresh\n",
    "ts_parameters = {\n",
    "    \"sum_values\": None,\n",
    "    \"variance\": None,\n",
    "    \"standard_deviation\": None,\n",
    "    \"mean\": None,\n",
    "    \"median\": None,\n",
    "    \"minimum\": None,\n",
    "    \"maximum\": None,\n",
    "    \"mean_change\": None,\n",
    "    \"root_mean_square\": None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d6c541c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 30/30 [00:07<00:00,  4.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# define output file\n",
    "output = 'dataout\\\\intensity_combined.csv'\n",
    "    \n",
    "# extract summary statistics \n",
    "summary_features = extract_features(df124_final, default_fc_parameters=ts_parameters, column_id=\"donor_id\", column_sort=\"timestamp\")\n",
    "  \n",
    "# reset index, \n",
    "summary_features.reset_index(inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49d7dc83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>donor_id</th>\n",
       "      <th>au01_r__sum_values</th>\n",
       "      <th>au01_r__variance</th>\n",
       "      <th>au01_r__standard_deviation</th>\n",
       "      <th>au01_r__mean</th>\n",
       "      <th>au01_r__median</th>\n",
       "      <th>au01_r__minimum</th>\n",
       "      <th>au01_r__maximum</th>\n",
       "      <th>au01_r__mean_change</th>\n",
       "      <th>au01_r__root_mean_square</th>\n",
       "      <th>...</th>\n",
       "      <th>au26_r__root_mean_square</th>\n",
       "      <th>au45_r__sum_values</th>\n",
       "      <th>au45_r__variance</th>\n",
       "      <th>au45_r__standard_deviation</th>\n",
       "      <th>au45_r__mean</th>\n",
       "      <th>au45_r__median</th>\n",
       "      <th>au45_r__minimum</th>\n",
       "      <th>au45_r__maximum</th>\n",
       "      <th>au45_r__mean_change</th>\n",
       "      <th>au45_r__root_mean_square</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1569.79</td>\n",
       "      <td>0.243053</td>\n",
       "      <td>0.493004</td>\n",
       "      <td>0.259469</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.48</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.557115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507946</td>\n",
       "      <td>2100.68</td>\n",
       "      <td>0.445580</td>\n",
       "      <td>0.667518</td>\n",
       "      <td>0.347220</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.752424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2179.09</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.577345</td>\n",
       "      <td>0.369337</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.12</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>0.685374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815290</td>\n",
       "      <td>1912.63</td>\n",
       "      <td>0.306231</td>\n",
       "      <td>0.553382</td>\n",
       "      <td>0.324175</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.641343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2341.13</td>\n",
       "      <td>0.249784</td>\n",
       "      <td>0.499784</td>\n",
       "      <td>0.284636</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.22</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>0.575154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979199</td>\n",
       "      <td>6828.36</td>\n",
       "      <td>1.708007</td>\n",
       "      <td>1.306908</td>\n",
       "      <td>0.830196</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>1.548300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2934.72</td>\n",
       "      <td>0.169020</td>\n",
       "      <td>0.411120</td>\n",
       "      <td>0.278833</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.33</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965606</td>\n",
       "      <td>5096.90</td>\n",
       "      <td>0.487540</td>\n",
       "      <td>0.698241</td>\n",
       "      <td>0.484266</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.849737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>2074.14</td>\n",
       "      <td>0.167990</td>\n",
       "      <td>0.409866</td>\n",
       "      <td>0.249896</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799094</td>\n",
       "      <td>4667.12</td>\n",
       "      <td>0.857760</td>\n",
       "      <td>0.926153</td>\n",
       "      <td>0.562304</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.64</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>1.083487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   donor_id  au01_r__sum_values  au01_r__variance  au01_r__standard_deviation  \\\n",
       "0         5             1569.79          0.243053                    0.493004   \n",
       "1         6             2179.09          0.333328                    0.577345   \n",
       "2         7             2341.13          0.249784                    0.499784   \n",
       "3         8             2934.72          0.169020                    0.411120   \n",
       "4         9             2074.14          0.167990                    0.409866   \n",
       "\n",
       "   au01_r__mean  au01_r__median  au01_r__minimum  au01_r__maximum  \\\n",
       "0      0.259469            0.03              0.0             4.48   \n",
       "1      0.369337            0.03              0.0             4.12   \n",
       "2      0.284636            0.00              0.0             4.22   \n",
       "3      0.278833            0.06              0.0             4.33   \n",
       "4      0.249896            0.01              0.0             3.40   \n",
       "\n",
       "   au01_r__mean_change  au01_r__root_mean_square  ...  \\\n",
       "0             0.000321                  0.557115  ...   \n",
       "1            -0.000063                  0.685374  ...   \n",
       "2            -0.000060                  0.575154  ...   \n",
       "3             0.000000                  0.496757  ...   \n",
       "4             0.000000                  0.480040  ...   \n",
       "\n",
       "   au26_r__root_mean_square  au45_r__sum_values  au45_r__variance  \\\n",
       "0                  0.507946             2100.68          0.445580   \n",
       "1                  0.815290             1912.63          0.306231   \n",
       "2                  0.979199             6828.36          1.708007   \n",
       "3                  0.965606             5096.90          0.487540   \n",
       "4                  0.799094             4667.12          0.857760   \n",
       "\n",
       "   au45_r__standard_deviation  au45_r__mean  au45_r__median  au45_r__minimum  \\\n",
       "0                    0.667518      0.347220            0.00              0.0   \n",
       "1                    0.553382      0.324175            0.02              0.0   \n",
       "2                    1.306908      0.830196            0.05              0.0   \n",
       "3                    0.698241      0.484266            0.09              0.0   \n",
       "4                    0.926153      0.562304            0.05              0.0   \n",
       "\n",
       "   au45_r__maximum  au45_r__mean_change  au45_r__root_mean_square  \n",
       "0             3.95             0.000000                  0.752424  \n",
       "1             3.17             0.000154                  0.641343  \n",
       "2             5.00            -0.000035                  1.548300  \n",
       "3             3.80             0.000095                  0.849737  \n",
       "4             4.64             0.000194                  1.083487  \n",
       "\n",
       "[5 rows x 154 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rename columns, rename index as donor_id \n",
    "summary_features.rename(columns={'index':'donor_id'}, inplace=True)\n",
    "    \n",
    "# extract csv file for stage1\n",
    "summary_features.to_csv(output, index=False)\n",
    "summary_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db98be05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# further check number of observations --> some csv files are not available in the main FAINT folder\n",
    "\n",
    "# not_available in df1--> [212, 213, 214, 215, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276]\n",
    "# not_available in df2--> [49, 55, 212, 213, 214, 215, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 332]\n",
    "# not_available in df4--> [56, 86, 212, 213, 214, 215, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 324, 328]\n",
    "\n",
    "assert df1['donor_id'].nunique()==310\n",
    "assert df2['donor_id'].nunique()==307\n",
    "assert df4['donor_id'].nunique()==308"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38167b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy master datasets for intensities\n",
    "df_master= pd.read_csv( rf'C:\\\\Users\\\\mtyur\\\\Desktop\\\\FAINT\\\\dataout\\\\intensity_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "888270c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>donor_id</th>\n",
       "      <th>au01_r__sum_values</th>\n",
       "      <th>au01_r__variance</th>\n",
       "      <th>au01_r__standard_deviation</th>\n",
       "      <th>au01_r__mean</th>\n",
       "      <th>au01_r__median</th>\n",
       "      <th>au01_r__minimum</th>\n",
       "      <th>au01_r__maximum</th>\n",
       "      <th>au01_r__mean_change</th>\n",
       "      <th>au01_r__root_mean_square</th>\n",
       "      <th>...</th>\n",
       "      <th>au26_r__root_mean_square</th>\n",
       "      <th>au45_r__sum_values</th>\n",
       "      <th>au45_r__variance</th>\n",
       "      <th>au45_r__standard_deviation</th>\n",
       "      <th>au45_r__mean</th>\n",
       "      <th>au45_r__median</th>\n",
       "      <th>au45_r__minimum</th>\n",
       "      <th>au45_r__maximum</th>\n",
       "      <th>au45_r__mean_change</th>\n",
       "      <th>au45_r__root_mean_square</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1569.79</td>\n",
       "      <td>0.243053</td>\n",
       "      <td>0.493004</td>\n",
       "      <td>0.259469</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.48</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.557115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507946</td>\n",
       "      <td>2100.68</td>\n",
       "      <td>0.445580</td>\n",
       "      <td>0.667518</td>\n",
       "      <td>0.347220</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.752424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2179.09</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.577345</td>\n",
       "      <td>0.369337</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.12</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>0.685374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815290</td>\n",
       "      <td>1912.63</td>\n",
       "      <td>0.306231</td>\n",
       "      <td>0.553382</td>\n",
       "      <td>0.324175</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.641343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2341.13</td>\n",
       "      <td>0.249784</td>\n",
       "      <td>0.499784</td>\n",
       "      <td>0.284636</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.22</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>0.575154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979199</td>\n",
       "      <td>6828.36</td>\n",
       "      <td>1.708007</td>\n",
       "      <td>1.306908</td>\n",
       "      <td>0.830196</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>1.548300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2934.72</td>\n",
       "      <td>0.169020</td>\n",
       "      <td>0.411120</td>\n",
       "      <td>0.278833</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.33</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965606</td>\n",
       "      <td>5096.90</td>\n",
       "      <td>0.487540</td>\n",
       "      <td>0.698241</td>\n",
       "      <td>0.484266</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.849737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>2074.14</td>\n",
       "      <td>0.167990</td>\n",
       "      <td>0.409866</td>\n",
       "      <td>0.249896</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799094</td>\n",
       "      <td>4667.12</td>\n",
       "      <td>0.857760</td>\n",
       "      <td>0.926153</td>\n",
       "      <td>0.562304</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.64</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>1.083487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   donor_id  au01_r__sum_values  au01_r__variance  au01_r__standard_deviation  \\\n",
       "0         5             1569.79          0.243053                    0.493004   \n",
       "1         6             2179.09          0.333328                    0.577345   \n",
       "2         7             2341.13          0.249784                    0.499784   \n",
       "3         8             2934.72          0.169020                    0.411120   \n",
       "4         9             2074.14          0.167990                    0.409866   \n",
       "\n",
       "   au01_r__mean  au01_r__median  au01_r__minimum  au01_r__maximum  \\\n",
       "0      0.259469            0.03              0.0             4.48   \n",
       "1      0.369337            0.03              0.0             4.12   \n",
       "2      0.284636            0.00              0.0             4.22   \n",
       "3      0.278833            0.06              0.0             4.33   \n",
       "4      0.249896            0.01              0.0             3.40   \n",
       "\n",
       "   au01_r__mean_change  au01_r__root_mean_square  ...  \\\n",
       "0             0.000321                  0.557115  ...   \n",
       "1            -0.000063                  0.685374  ...   \n",
       "2            -0.000060                  0.575154  ...   \n",
       "3             0.000000                  0.496757  ...   \n",
       "4             0.000000                  0.480040  ...   \n",
       "\n",
       "   au26_r__root_mean_square  au45_r__sum_values  au45_r__variance  \\\n",
       "0                  0.507946             2100.68          0.445580   \n",
       "1                  0.815290             1912.63          0.306231   \n",
       "2                  0.979199             6828.36          1.708007   \n",
       "3                  0.965606             5096.90          0.487540   \n",
       "4                  0.799094             4667.12          0.857760   \n",
       "\n",
       "   au45_r__standard_deviation  au45_r__mean  au45_r__median  au45_r__minimum  \\\n",
       "0                    0.667518      0.347220            0.00              0.0   \n",
       "1                    0.553382      0.324175            0.02              0.0   \n",
       "2                    1.306908      0.830196            0.05              0.0   \n",
       "3                    0.698241      0.484266            0.09              0.0   \n",
       "4                    0.926153      0.562304            0.05              0.0   \n",
       "\n",
       "   au45_r__maximum  au45_r__mean_change  au45_r__root_mean_square  \n",
       "0             3.95             0.000000                  0.752424  \n",
       "1             3.17             0.000154                  0.641343  \n",
       "2             5.00            -0.000035                  1.548300  \n",
       "3             3.80             0.000095                  0.849737  \n",
       "4             4.64             0.000194                  1.083487  \n",
       "\n",
       "[5 rows x 154 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23643a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique observation:\n",
      "313\n"
     ]
    }
   ],
   "source": [
    "# check master dataset\n",
    "print (\"Number of unique observation:\")\n",
    "print(df_master['donor_id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a373032a",
   "metadata": {},
   "source": [
    "####  Keep master dataset for demographics, vvr scores and somatosensory amplification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "830ca696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload csv file reporting the responses to the FAINT questionnaire\n",
    "df_personal= pd.read_csv( 'C:\\\\Users\\\\mtyur\\\\Desktop\\\\FAINT\\\\datain_p\\\\FAINT_alldatafromallparticipants.csv')\n",
    "\n",
    "# define neccessary variables\n",
    "keep_var=['ID','Condition', 'Gender', 'Age', 'BMI', 'Q4.1_1', 'Q4.1_2', 'Q4.1_3', 'Q4.1_4', 'Q4.1_5', 'Q4.1_6','Q4.1_7', 'Q4.1_8', 'Q4.1_9', 'Q4.1_10']\n",
    "\n",
    "# filter the personal questionnaire, keep main demographics (same across time_points)\n",
    "df_personal_master= df_personal.loc[df_personal['Time_point']==4, keep_var].copy()\n",
    "\n",
    "# reset index\n",
    "df_personal_master.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d79271a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep subset of main questionnaire dataset (stage 4 to 7 with vvr subscores)\n",
    "df_personal_long = df_personal.loc[df_personal['Time_point'].isin([4,5,6,7]),['ID','Time_point', 'VVR_psych_tp', 'VVR_phys_tp']].copy()\n",
    "\n",
    "# create wide format of the personal questionnaire\n",
    "df_personal_wide=df_personal_long.pivot_table(index='ID', columns='Time_point', values={'VVR_psych_tp', 'VVR_phys_tp'}, aggfunc='mean')\n",
    "\n",
    "# rename columns to remove multi-ndexing\n",
    "df_personal_wide.columns=['_'.join(map(str,col)).strip() for col in df_personal_wide.columns.values]\n",
    "\n",
    "# keep index value as donor_id\n",
    "df_personal_wide.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07c224f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge vvr scores with main demographics \n",
    "df_master_p = pd.merge(df_personal_master, df_personal_wide, on='ID', how= 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01dad652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename ID column as donor_id -- will be useful to merge with AU intensities\n",
    "df_master_p.rename(columns={'ID':'donor_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbef4bc7",
   "metadata": {},
   "source": [
    "####  Merge master dataset on facial action units with master dataset on personal questionnaire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f243874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge master_intensity dataset with preprocessed master personal dataset \n",
    "df_final_raw = pd.merge(df_master_p, df_master, on='donor_id', how= 'outer')\n",
    "\n",
    "# extract csv file for final master dataset\n",
    "# define output file\n",
    "output_final =  'dataout\\preprocessed_faint.csv'\n",
    "df_final_raw.to_csv(output_final, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c0f6d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>donor_id</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Q4.1_1</th>\n",
       "      <th>Q4.1_2</th>\n",
       "      <th>Q4.1_3</th>\n",
       "      <th>Q4.1_4</th>\n",
       "      <th>Q4.1_5</th>\n",
       "      <th>...</th>\n",
       "      <th>au26_r__root_mean_square</th>\n",
       "      <th>au45_r__sum_values</th>\n",
       "      <th>au45_r__variance</th>\n",
       "      <th>au45_r__standard_deviation</th>\n",
       "      <th>au45_r__mean</th>\n",
       "      <th>au45_r__median</th>\n",
       "      <th>au45_r__minimum</th>\n",
       "      <th>au45_r__maximum</th>\n",
       "      <th>au45_r__mean_change</th>\n",
       "      <th>au45_r__root_mean_square</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>25.306932</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507946</td>\n",
       "      <td>2100.68</td>\n",
       "      <td>0.445580</td>\n",
       "      <td>0.667518</td>\n",
       "      <td>0.347220</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.752424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>27.763430</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815290</td>\n",
       "      <td>1912.63</td>\n",
       "      <td>0.306231</td>\n",
       "      <td>0.553382</td>\n",
       "      <td>0.324175</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.641343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.999459</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979199</td>\n",
       "      <td>6828.36</td>\n",
       "      <td>1.708007</td>\n",
       "      <td>1.306908</td>\n",
       "      <td>0.830196</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>1.548300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>27.458654</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965606</td>\n",
       "      <td>5096.90</td>\n",
       "      <td>0.487540</td>\n",
       "      <td>0.698241</td>\n",
       "      <td>0.484266</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.849737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>26.122449</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799094</td>\n",
       "      <td>4667.12</td>\n",
       "      <td>0.857760</td>\n",
       "      <td>0.926153</td>\n",
       "      <td>0.562304</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.64</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>1.083487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   donor_id  Condition  Gender   Age        BMI  Q4.1_1  Q4.1_2  Q4.1_3  \\\n",
       "0         5        1.0     2.0  33.0  25.306932     2.0     3.0     4.0   \n",
       "1         6        2.0     1.0  33.0  27.763430     2.0     2.0     3.0   \n",
       "2         7        2.0     2.0  25.0  23.999459     1.0     1.0     1.0   \n",
       "3         8        1.0     1.0  56.0  27.458654     1.0     2.0     4.0   \n",
       "4         9        1.0     1.0  41.0  26.122449     1.0     5.0     4.0   \n",
       "\n",
       "   Q4.1_4  Q4.1_5  ...  au26_r__root_mean_square  au45_r__sum_values  \\\n",
       "0     2.0     4.0  ...                  0.507946             2100.68   \n",
       "1     1.0     1.0  ...                  0.815290             1912.63   \n",
       "2     4.0     1.0  ...                  0.979199             6828.36   \n",
       "3     1.0     1.0  ...                  0.965606             5096.90   \n",
       "4     1.0     1.0  ...                  0.799094             4667.12   \n",
       "\n",
       "   au45_r__variance  au45_r__standard_deviation  au45_r__mean  au45_r__median  \\\n",
       "0          0.445580                    0.667518      0.347220            0.00   \n",
       "1          0.306231                    0.553382      0.324175            0.02   \n",
       "2          1.708007                    1.306908      0.830196            0.05   \n",
       "3          0.487540                    0.698241      0.484266            0.09   \n",
       "4          0.857760                    0.926153      0.562304            0.05   \n",
       "\n",
       "   au45_r__minimum  au45_r__maximum  au45_r__mean_change  \\\n",
       "0              0.0             3.95             0.000000   \n",
       "1              0.0             3.17             0.000154   \n",
       "2              0.0             5.00            -0.000035   \n",
       "3              0.0             3.80             0.000095   \n",
       "4              0.0             4.64             0.000194   \n",
       "\n",
       "   au45_r__root_mean_square  \n",
       "0                  0.752424  \n",
       "1                  0.641343  \n",
       "2                  1.548300  \n",
       "3                  0.849737  \n",
       "4                  1.083487  \n",
       "\n",
       "[5 rows x 176 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_raw.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
